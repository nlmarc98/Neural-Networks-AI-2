# The activation function

def linear_threshold(x, theta=0):
    if theta >= x:
        return 0
    else:
        return 1 
        
# Output of a perceptron

def compute_output(x,w):
    return linear_threshold(np.dot(w, x))

# Perceptron weight update

def update_weights(w, x, y, t):
    w =  w + (t - y)*x
    



def perceptron_train(X, T, num_epochs=10):
    m, n = X.shape

    # Initialize the right number of weights as zeros
    w= np.zeros([X.shape[0],])
 
   
    # Loop over epochs
    for i in range(num_epochs):
        # Loop over all examples in random order
        for j in np.random.permutation(X[m:,]):
            for k in np.random.permutation(X[:,n]):                
                # Take an example
                example = X[j,k]
                y=linear_threshold(compute_output(example, w))
                w+= update_weights(w,example,y,T)
            
            
    return w




def perceptron_test(X, w):
    n = X.shape[1]
   
    # Create an output array Y that you use to store the perceptron outputs
    Y=[]
    # Loop over the examples
    for i in range(n):
         # Take an example
        example= X[:,i]
        y=linear_threshold(compute_output(example, w))
        Y.append(y)
        # Compute the output of the perceptron
    
    return Y
   
