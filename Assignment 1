7
# Linear threshold activation function: 
def step(x):
    if x >= 1 :
        return 1
    else:
        return 0
    
# Plot activation over given range: 
values=[]

for i in range(-10,11):
    s = step(i)
    values.append(s)

plt.plot(range(-10,11), values)
plt.title('step activation function over the input range [-10, 10]')
plt.xlabel('x')
plt.ylabel('step(x)')
plt.grid()
plt.show()

8
# Linear sigmoid activation function: 
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Plot activation over given range: 
values=[]

for i in range(-10,11):
    s = sigmoid(i)
    values.append(s)
    
plt.plot(range(-10,11),values)
plt.title('sigmoid activation function over the input range [-10, 10]')
plt.xlabel('x')
plt.ylabel('sigmoid(x)')
plt.show()

9.1
# Write a for-loop
for i in range(0, len(x_inputs)):
    activation_input = (x_inputs[i]*weights[i]) + activation_input

9.2
###############How is the operation called? â†’ Inner product

activation_input = 0.0

# Write a one-liner
activation_input = np.inner(weights, x_inputs)

10.1
# Write a for-loop       
for i in range(0, len(weights)):   
    for j in range(0, len(x_inputs)):
        activation_inputs[i] = (x_inputs[j]*weights[i,j]) + activation_inputs[i]

10.2
# Write a one-liner
activation_inputs = np.inner(weights, x_inputs)

10.3
# Write a one-liner
activation_inputs = np.inner(weights, x_inputs)
